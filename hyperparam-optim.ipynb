{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models that require no preprocessing\n",
    "* Decision Tree\n",
    "* Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimised Parameters: {'estimator__max_depth': 100, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__n_estimators': 300}\n",
      "Cross-validated accuracy: 0.4723\n",
      "Cross-validated f1: 0.4576\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from ml_methods.data_prep import add_authors_as_features\n",
    "\n",
    "\n",
    "songs = pd.read_csv('data/spotify_clean.csv', index_col=[0])\n",
    "songs_data = add_authors_as_features(songs, 2000)\n",
    "songs_data = songs.drop(columns = [\"track_id\", \"artists\", \"album_name\", \"track_name\", \"track_genre\"])\n",
    "genres = songs[\"track_genre\"]\n",
    "\n",
    "# Numerically encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_genres = label_encoder.fit_transform(genres)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(songs_data, encoded_genres, test_size=0.3,\n",
    "                                                    stratify=encoded_genres, shuffle=True, random_state=100)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=100)\n",
    "model = RandomForestClassifier()\n",
    "pipeline = Pipeline([\n",
    "    ('estimator', model)])\n",
    "\n",
    "parameters = {\n",
    "    'estimator__n_estimators': [100, 200, 300],\n",
    "    'estimator__max_depth':[None, 20, 50, 100],\n",
    "    'estimator__min_samples_split' :[2, 100, 200],\n",
    "    'estimator__min_samples_leaf':[1, 10, 50, 100]\n",
    "}\n",
    "\n",
    "# create the grid search estimator\n",
    "grid_search_estimator = GridSearchCV(pipeline, parameters, scoring='f1_weighted', cv=cv)\n",
    "# fit the grid search (= determine the optimal parameters)\n",
    "grid_search_estimator.fit(X_train.values, y_train)\n",
    "\n",
    "# Get the best parameters and best model\n",
    "best_params = grid_search_estimator.best_params_\n",
    "best_model = grid_search_estimator.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_predictions = best_model.predict(X_test)\n",
    "best_accuracy = accuracy_score(y_test, best_predictions)\n",
    "best_f1_weighted = f1_score(y_test, best_predictions, average='weighted')\n",
    "print(\"Optimised Parameters: {}\".format(grid_search_estimator.best_params_))\n",
    "print(f\"Cross-validated accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"Cross-validated f1: {best_f1_weighted:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models that require preprocessing\n",
    "* All other models used StandardScaler to normalise the data to unit variance and zero mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "songs = pd.read_csv('data/spotify_simplified.csv', index_col=[0])\n",
    "songs_data = songs.drop(columns = [\"track_id\", \"artists\", \"album_name\", \"track_name\", \"track_genre\"])\n",
    "genres = songs[\"track_genre\"]\n",
    "\n",
    "# Numerically encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_genres = label_encoder.fit_transform(genres)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(songs_data, encoded_genres, test_size=0.3,\n",
    "                                                    stratify=encoded_genres, shuffle=True, random_state=100)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=100)\n",
    "scaler = StandardScaler()\n",
    "model = DecisionTreeClassifier()\n",
    "pipeline = Pipeline([('normalisation', scaler), ('estimator', model)])\n",
    "\n",
    "parameters = {\n",
    "    'estimator__max_depth':[15, 70, 150, 200],\n",
    "    'estimator__min_samples_split' :[10, 50, 100, 200],\n",
    "    'estimator__min_samples_leaf':[5, 50, 100]\n",
    "}\n",
    "pipeline = Pipeline([\n",
    "    ('estimator', DecisionTreeClassifier())])\n",
    "# create the grid search estimator\n",
    "grid_search_estimator = GridSearchCV(pipeline, parameters, scoring='f1_weighted', cv=cv)\n",
    "# fit the grid search (= determine the optimal parameters)\n",
    "grid_search_estimator.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best model\n",
    "best_params = grid_search_estimator.best_params_\n",
    "best_model = grid_search_estimator.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_predictions = best_model.predict(X_test)\n",
    "best_accuracy = accuracy_score(y_test, best_predictions)\n",
    "best_f1_weighted = f1_score(y_test, best_predictions, average='weighted')\n",
    "print(\"Optimised Parameters: {}\".format(grid_search_estimator.best_params_))\n",
    "print(f\"Cross-validated accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"Cross-validated f1: {best_f1_weighted:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
